{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485064dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray, vstack, savez_compressed\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, smart_resize, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2024c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop and scale scale image\n",
    "def scale(path, height, width):\n",
    "    \n",
    "    # load a scaled version of the image\n",
    "    img = load_img(path, target_size=(height,width))\n",
    "    \n",
    "    # set the box based which side is larger\n",
    "    if height < width:\n",
    "        left = (width - 256) / 2\n",
    "        top = 0\n",
    "        right = width - ((width - 256) / 2)\n",
    "        bottom = height\n",
    "        \n",
    "        img = img.crop((left,top,right,bottom))\n",
    "    elif width < height:\n",
    "        left = 0\n",
    "        top = (height - 256) / 2\n",
    "        right = width\n",
    "        bottom = height - ((height - 256) / 2)\n",
    "        \n",
    "        img = img.crop((left,top,right,bottom))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bedadf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load, rescale and crop a dataset into 256x256\n",
    "def load_scale_crop(path, stop=0):\n",
    "    \n",
    "    data_list = list()\n",
    "    count = 0\n",
    "    \n",
    "    # enumerate filenames in directory\n",
    "    for filename in listdir(path):\n",
    "        \n",
    "        if filename == 'desktop.ini':\n",
    "            continue\n",
    "        \n",
    "        if count >= stop and stop != 0:\n",
    "            break\n",
    "        \n",
    "        img = load_img(path+filename)\n",
    "        img = img_to_array(img)\n",
    "        \n",
    "        if img.shape[0] < img.shape[1]:\n",
    "            height = int(img.shape[0] / (img.shape[0] / 256))\n",
    "            width = int(img.shape[1] / (img.shape[0] / 256))\n",
    "            \n",
    "            formated = scale(path+filename, height, width)\n",
    "            \n",
    "            formated = img_to_array(formated)\n",
    "            \n",
    "            data_list.append(formated)\n",
    "        elif img.shape[1] < img.shape[0]:\n",
    "            height = int(img.shape[0] / (img.shape[1] / 256))\n",
    "            width = int(img.shape[1] / (img.shape[1] / 256))\n",
    "            \n",
    "            formated = scale(path+filename, height, width)\n",
    "            \n",
    "            formated = img_to_array(formated)\n",
    "            \n",
    "            data_list.append(formated)\n",
    "        else:\n",
    "            height = int(img.shape[0] / (img.shape[0]/ 256))\n",
    "            width = int(img.shape[1] / (img.shape[1]/ 256))\n",
    "            \n",
    "            formated = load_img(path+filename, target_size=(height,width))\n",
    "            \n",
    "            formated = img_to_array(formated)\n",
    "            \n",
    "            data_list.append(formated)\n",
    "            \n",
    "        count += 1\n",
    "            \n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad3b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_crop_save(old_path, new_path, filename, stop=0):\n",
    "    \n",
    "    data = load_scale_crop(old_path, stop)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for array in data:\n",
    "        \n",
    "        if count >= 300:\n",
    "            break\n",
    "            \n",
    "        img = array_to_img(array)\n",
    "        img.save(f'{new_path}{count}{filename}.jpg', 'JPEG')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648e1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desktop.ini'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('people_bjarki/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2d161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_crop_save('train2014_usable/', 'data/photo/', '2014_usab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a68a3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce4f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataB:  (1514, 256, 256, 3)\n",
      "DataA:  (1514, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# stop condition\n",
    "stop = len(listdir('Munch_Cleaned_Types/'))\n",
    "\n",
    "# dataset path\n",
    "path = 'Munch_Cleaned_Types/'\n",
    "\n",
    "# load, split and stack dataset B\n",
    "dataB = load_scale_crop(path, stop)\n",
    "trainB, testB = train_test_split(dataB, test_size=0.3)\n",
    "dataB = vstack((trainB, testB))\n",
    "print('DataB: ', dataB.shape)\n",
    "\n",
    "# update path\n",
    "path = 'data/photo_jpg/'\n",
    "\n",
    "# load, split and stack dataset A\n",
    "dataA = load_scale_crop(path, stop)\n",
    "trainA, testA = train_test_split(dataA, test_size=0.3)\n",
    "dataA = vstack((trainA, testA))\n",
    "print('DataA: ', dataA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f938d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset:  photo2munch_cleaned_sametype_256.npz\n"
     ]
    }
   ],
   "source": [
    "# save as compressed numpy array\n",
    "filename = 'photo2munch_cleaned_sametype_256.npz'\n",
    "savez_compressed(filename, a=dataA, b=dataB)\n",
    "print('Saved dataset: ', filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
