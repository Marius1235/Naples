{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b30e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49df569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac9ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e44d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Munchify(model, input_image):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # open and transform image to be syle transfered\n",
    "    image = input_image\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # use generator to perform style transfer\n",
    "    image = model(image).detach()\n",
    "\n",
    "    # get correct dimensions, to ndarray, as image, and save\n",
    "    image = image.squeeze().numpy()\n",
    "    image = ((image + 1) / 2) * 256\n",
    "    image = image.astype(np.uint8).transpose(1,2,0)\n",
    "    img = Image.fromarray(image, 'RGB')\n",
    "    \n",
    "    # create byte array, save image in byte array, convert to base64\n",
    "    byte_arr = io.BytesIO()\n",
    "    img.save(byte_arr, format='JPEG')\n",
    "    byte_arr = byte_arr.getvalue()\n",
    "    img_str = base64.b64encode(byte_arr).decode()\n",
    "    \n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a96d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.105.221:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [15/Jun/2023 09:22:08] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:25:53] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:29:13] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:41:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:43:49] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:45:43] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:47:42] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:49:17] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:51:14] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:53:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:55:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:56:57] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 09:59:10] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 10:20:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 10:33:03] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 10:46:35] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jun/2023 10:57:46] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_block):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "        \n",
    "        channels = input_shape[0]\n",
    "        \n",
    "        # Initial Convolution Block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(channels),\n",
    "            nn.Conv2d(channels, out_features, 7),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        in_features = out_features\n",
    "        \n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "        \n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_block):\n",
    "            model += [ResidualBlock(out_features)]\n",
    "            \n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            \n",
    "        # Output Layer\n",
    "        model += [nn.ReflectionPad2d(channels),\n",
    "                  nn.Conv2d(out_features, channels, 7),\n",
    "                  nn.Tanh()\n",
    "                 ]\n",
    "        \n",
    "        # Unpacking\n",
    "        self.model = nn.Sequential(*model) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "g_models = []\n",
    "\n",
    "path = \"models/\"\n",
    "\n",
    "for model in os.listdir(path):\n",
    "    if model == \".DS_Store\":\n",
    "        continue\n",
    "    g_model = GeneratorResNet((3,256,256), 9)\n",
    "    model_checkpoint = torch.load(path+model, map_location=device)\n",
    "    g_model.load_state_dict(model_checkpoint['state_dict'])\n",
    "    g_model.to(device)\n",
    "    g_model.eval()\n",
    "    g_models.append(g_model)\n",
    "    \n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            file = Image.open(io.BytesIO(request.files['file'].read()))\n",
    "                \n",
    "            results = {}\n",
    "            \n",
    "            i = 1\n",
    "            \n",
    "            for model in g_models:\n",
    "                result = Munchify(model, file)\n",
    "                results[f'result{i}'] = result\n",
    "                i += 1\n",
    "            \n",
    "            return jsonify(results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return jsonify({'error': str(e)}), 400\n",
    "        \n",
    "       \n",
    "        \n",
    "@app.route('/', methods=['GET'])    \n",
    "def home():\n",
    "    return \"hello, world!\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3de367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
